{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 3\n",
    "Due Tuesday (week 4). Answer the following questions.\n",
    "\n",
    "1. Define Random forest. How is it used with regression, i.e. random forest regressor?\n",
    "2. Define stochastic gradient descent\n",
    "3. Define grid search. Using the iris dataset and J48, vary the confidence parameter and minimum node size. Find the value that give the greatest accuracy.\n",
    "4. Write a Python function to read a csv file (contact lens dataset)\n",
    "5. Write a Python function to compute standard deviation.\n",
    "6. Run multilayer perceptron on MNIST. Compute precision and recall.\n",
    "7. Read Ch. 4 in TensorFlow book\n",
    "8. Also read Ch4 in Data Mining."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1\n",
    "\n",
    "Define *Random Forest*. How is it used with regression? (i.e. random forest regressor)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Random Forest is a technique that randomply partitions data into sub-samples\n",
    "and generates classification trees for each of the the subsamples. Then, the\n",
    "outputs of the trees are analyzed and the error function of the model is\n",
    "minimized by selecting appropriate variables for each node and/or adjusting\n",
    "weights for the regression function based on this output data.\n",
    "\n",
    "Random forest is great because it can significantly reduce computational \n",
    "overhead when used correctly.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2\n",
    "\n",
    "Define stochastic gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Stochastic Gradient Descent is an iterative, incremental algorithm\n",
    "that works by minimizing the error function of a predictor. It updates\n",
    "its model instance-by-nstance or in small batches.\n",
    "\n",
    "Stochastic Gradient Descent (SGD), like Gradient Descent (GD), updates a \n",
    "set of parameters iteratively in order to minimize the error.\n",
    "\n",
    "The difference is that with SGD, rather than using the entire dataset\n",
    "to update a parameter/weight in a particular iteration, you can use as few\n",
    "as one instance to update a parameter.\n",
    "\n",
    "The reason why SGD is used is because when training on massive datasets\n",
    "it simply takes too long to use the entire dataset to update a parameter.\n",
    "\n",
    "SGD is a close approximate to GD, so its error function won't be quite as\n",
    "optimal, and it converges more quickly, but in the real world it is obviously\n",
    "good enough in many cases.\n",
    "\n",
    "Mathematically thinking, if we imagine this geometrically, GD and SGD attempt\n",
    "to find the quickest downward slope to reach the bottom of a valley. So\n",
    "Gradient Descent techniques find the quickest way \"downhill\" to a minimized\n",
    "error.\n",
    "\n",
    "Stochastic kind of means \"chaotic\" or \"random\", and so we can imagine that \n",
    "the path SGD takes to the bottom of the hill is a little bit zig-zaggy (like \n",
    "a graph of the stock market, or the meandering of a particle in water). It's\n",
    "a bit less direct that GD on account of this.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3\n",
    "\n",
    "Define grid search. Using the iris dataset and J48, vary the confidence parameter and minimum node size. Find the value that give the greatest accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yeah again, this simply isn't working. Like I've said in my labs,\n",
    "# I've searched high and low and can't get this to work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4\n",
    "\n",
    "Write a Python function to read a csv file (contact lens dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age, spectacle-prescrip, astigmatism, tear-prod-rate, contact-lenses\n",
      "young, myope, no, reduced, none\n",
      "young, myope, no, normal, soft\n",
      "young, myope, yes, reduced, none\n",
      "young, myope, yes, normal, hard\n",
      "young, hypermetrope, no, reduced, none\n",
      "young, hypermetrope, no, normal, soft\n",
      "young, hypermetrope, yes, reduced, none\n",
      "young, hypermetrope, yes, normal, hard\n",
      "pre-presbyopic, myope, no, reduced, none\n",
      "pre-presbyopic, myope, no, normal, soft\n",
      "pre-presbyopic, myope, yes, reduced, none\n",
      "pre-presbyopic, myope, yes, normal, hard\n",
      "pre-presbyopic, hypermetrope, no, reduced, none\n",
      "pre-presbyopic, hypermetrope, no, normal, soft\n",
      "pre-presbyopic, hypermetrope, yes, reduced, none\n",
      "pre-presbyopic, hypermetrope, yes, normal, none\n",
      "presbyopic, myope, no, reduced, none\n",
      "presbyopic, myope, no, normal, none\n",
      "presbyopic, myope, yes, reduced, none\n",
      "presbyopic, myope, yes, normal, hard\n",
      "presbyopic, hypermetrope, no, reduced, none\n",
      "presbyopic, hypermetrope, no, normal, soft\n",
      "presbyopic, hypermetrope, yes, reduced, none\n",
      "presbyopic, hypermetrope, yes, normal, none\n"
     ]
    }
   ],
   "source": [
    "# We can do this the old fashioned way, which\n",
    "# will be important to know if we want to write\n",
    "# any of our own algorithms from scratch\n",
    "\n",
    "import csv\n",
    "\n",
    "with open('contact-lenses.csv', newline='') as csvdata:\n",
    "        reader = csv.reader(csvdata, delimiter = ',')\n",
    "        for row in reader:\n",
    "            print(', '.join(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               age spectacle-prescrip astigmatism tear-prod-rate  \\\n",
      "0            young              myope          no        reduced   \n",
      "1            young              myope          no         normal   \n",
      "2            young              myope         yes        reduced   \n",
      "3            young              myope         yes         normal   \n",
      "4            young       hypermetrope          no        reduced   \n",
      "5            young       hypermetrope          no         normal   \n",
      "6            young       hypermetrope         yes        reduced   \n",
      "7            young       hypermetrope         yes         normal   \n",
      "8   pre-presbyopic              myope          no        reduced   \n",
      "9   pre-presbyopic              myope          no         normal   \n",
      "10  pre-presbyopic              myope         yes        reduced   \n",
      "11  pre-presbyopic              myope         yes         normal   \n",
      "12  pre-presbyopic       hypermetrope          no        reduced   \n",
      "13  pre-presbyopic       hypermetrope          no         normal   \n",
      "14  pre-presbyopic       hypermetrope         yes        reduced   \n",
      "15  pre-presbyopic       hypermetrope         yes         normal   \n",
      "16      presbyopic              myope          no        reduced   \n",
      "17      presbyopic              myope          no         normal   \n",
      "18      presbyopic              myope         yes        reduced   \n",
      "19      presbyopic              myope         yes         normal   \n",
      "20      presbyopic       hypermetrope          no        reduced   \n",
      "21      presbyopic       hypermetrope          no         normal   \n",
      "22      presbyopic       hypermetrope         yes        reduced   \n",
      "23      presbyopic       hypermetrope         yes         normal   \n",
      "\n",
      "   contact-lenses  \n",
      "0            none  \n",
      "1            soft  \n",
      "2            none  \n",
      "3            hard  \n",
      "4            none  \n",
      "5            soft  \n",
      "6            none  \n",
      "7            hard  \n",
      "8            none  \n",
      "9            soft  \n",
      "10           none  \n",
      "11           hard  \n",
      "12           none  \n",
      "13           soft  \n",
      "14           none  \n",
      "15           none  \n",
      "16           none  \n",
      "17           none  \n",
      "18           none  \n",
      "19           hard  \n",
      "20           none  \n",
      "21           soft  \n",
      "22           none  \n",
      "23           none  \n"
     ]
    }
   ],
   "source": [
    "# Or we can use Pandas to print everything nicely\n",
    "# Plus, Pandas is industry-standard for EDA and stats\n",
    "\n",
    "import pandas as pd\n",
    "print(pd.read_csv('contact-lenses.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>spectacle-prescrip</th>\n",
       "      <th>astigmatism</th>\n",
       "      <th>tear-prod-rate</th>\n",
       "      <th>contact-lenses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>young</td>\n",
       "      <td>myope</td>\n",
       "      <td>no</td>\n",
       "      <td>reduced</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>young</td>\n",
       "      <td>myope</td>\n",
       "      <td>no</td>\n",
       "      <td>normal</td>\n",
       "      <td>soft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>young</td>\n",
       "      <td>myope</td>\n",
       "      <td>yes</td>\n",
       "      <td>reduced</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>young</td>\n",
       "      <td>myope</td>\n",
       "      <td>yes</td>\n",
       "      <td>normal</td>\n",
       "      <td>hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>young</td>\n",
       "      <td>hypermetrope</td>\n",
       "      <td>no</td>\n",
       "      <td>reduced</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>young</td>\n",
       "      <td>hypermetrope</td>\n",
       "      <td>no</td>\n",
       "      <td>normal</td>\n",
       "      <td>soft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>young</td>\n",
       "      <td>hypermetrope</td>\n",
       "      <td>yes</td>\n",
       "      <td>reduced</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>young</td>\n",
       "      <td>hypermetrope</td>\n",
       "      <td>yes</td>\n",
       "      <td>normal</td>\n",
       "      <td>hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>pre-presbyopic</td>\n",
       "      <td>myope</td>\n",
       "      <td>no</td>\n",
       "      <td>reduced</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>pre-presbyopic</td>\n",
       "      <td>myope</td>\n",
       "      <td>no</td>\n",
       "      <td>normal</td>\n",
       "      <td>soft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>pre-presbyopic</td>\n",
       "      <td>myope</td>\n",
       "      <td>yes</td>\n",
       "      <td>reduced</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>pre-presbyopic</td>\n",
       "      <td>myope</td>\n",
       "      <td>yes</td>\n",
       "      <td>normal</td>\n",
       "      <td>hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>pre-presbyopic</td>\n",
       "      <td>hypermetrope</td>\n",
       "      <td>no</td>\n",
       "      <td>reduced</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>pre-presbyopic</td>\n",
       "      <td>hypermetrope</td>\n",
       "      <td>no</td>\n",
       "      <td>normal</td>\n",
       "      <td>soft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>pre-presbyopic</td>\n",
       "      <td>hypermetrope</td>\n",
       "      <td>yes</td>\n",
       "      <td>reduced</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>pre-presbyopic</td>\n",
       "      <td>hypermetrope</td>\n",
       "      <td>yes</td>\n",
       "      <td>normal</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>presbyopic</td>\n",
       "      <td>myope</td>\n",
       "      <td>no</td>\n",
       "      <td>reduced</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>presbyopic</td>\n",
       "      <td>myope</td>\n",
       "      <td>no</td>\n",
       "      <td>normal</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>presbyopic</td>\n",
       "      <td>myope</td>\n",
       "      <td>yes</td>\n",
       "      <td>reduced</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>presbyopic</td>\n",
       "      <td>myope</td>\n",
       "      <td>yes</td>\n",
       "      <td>normal</td>\n",
       "      <td>hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>presbyopic</td>\n",
       "      <td>hypermetrope</td>\n",
       "      <td>no</td>\n",
       "      <td>reduced</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>presbyopic</td>\n",
       "      <td>hypermetrope</td>\n",
       "      <td>no</td>\n",
       "      <td>normal</td>\n",
       "      <td>soft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>presbyopic</td>\n",
       "      <td>hypermetrope</td>\n",
       "      <td>yes</td>\n",
       "      <td>reduced</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>presbyopic</td>\n",
       "      <td>hypermetrope</td>\n",
       "      <td>yes</td>\n",
       "      <td>normal</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               age spectacle-prescrip astigmatism tear-prod-rate  \\\n",
       "0            young              myope          no        reduced   \n",
       "1            young              myope          no         normal   \n",
       "2            young              myope         yes        reduced   \n",
       "3            young              myope         yes         normal   \n",
       "4            young       hypermetrope          no        reduced   \n",
       "5            young       hypermetrope          no         normal   \n",
       "6            young       hypermetrope         yes        reduced   \n",
       "7            young       hypermetrope         yes         normal   \n",
       "8   pre-presbyopic              myope          no        reduced   \n",
       "9   pre-presbyopic              myope          no         normal   \n",
       "10  pre-presbyopic              myope         yes        reduced   \n",
       "11  pre-presbyopic              myope         yes         normal   \n",
       "12  pre-presbyopic       hypermetrope          no        reduced   \n",
       "13  pre-presbyopic       hypermetrope          no         normal   \n",
       "14  pre-presbyopic       hypermetrope         yes        reduced   \n",
       "15  pre-presbyopic       hypermetrope         yes         normal   \n",
       "16      presbyopic              myope          no        reduced   \n",
       "17      presbyopic              myope          no         normal   \n",
       "18      presbyopic              myope         yes        reduced   \n",
       "19      presbyopic              myope         yes         normal   \n",
       "20      presbyopic       hypermetrope          no        reduced   \n",
       "21      presbyopic       hypermetrope          no         normal   \n",
       "22      presbyopic       hypermetrope         yes        reduced   \n",
       "23      presbyopic       hypermetrope         yes         normal   \n",
       "\n",
       "   contact-lenses  \n",
       "0            none  \n",
       "1            soft  \n",
       "2            none  \n",
       "3            hard  \n",
       "4            none  \n",
       "5            soft  \n",
       "6            none  \n",
       "7            hard  \n",
       "8            none  \n",
       "9            soft  \n",
       "10           none  \n",
       "11           hard  \n",
       "12           none  \n",
       "13           soft  \n",
       "14           none  \n",
       "15           none  \n",
       "16           none  \n",
       "17           none  \n",
       "18           none  \n",
       "19           hard  \n",
       "20           none  \n",
       "21           soft  \n",
       "22           none  \n",
       "23           none  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And if we're going for presentation or even easier\n",
    "# viewing, we can print our data as a dataframe in\n",
    "# iPython (Jupyter Notebook et al.)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(pd.read_csv('contact-lenses.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 5\n",
    "\n",
    "Write a Python function to compute standard deviation.\n",
    "\n",
    "\n",
    "$$ \\sigma = \\sqrt{\\frac{1}{N}\\sum^{N}_{i=1}(x_i-\\mu)^2}$$\n",
    "\n",
    "Calculating the Standard Deviation is a simple process that goes like this:\n",
    "\n",
    "1. Calculate the __Mean__\n",
    "2. For each individual instance, subtract the mean and square the result. In other words, __find the square differences of the mean of the dataset and each number in the dataset__.\n",
    "3. Then __take the mean of *those* squared differences__.\n",
    "4. Take __the square root of that__ resulting number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "These are pretty open-ended instructions. \n",
    "I suppose I'll just write a little function that\n",
    "finds the standard deviation of a list of numbers.\n",
    "'''\n",
    "\n",
    "## Highly readable version:\n",
    "def std_easy(il):\n",
    "    mean = sum(il) / len(il)\n",
    "    squared_diffs = [(i - mean)**2 for i in il]\n",
    "    mean_ = sum(squared_diffs) / len(il)\n",
    "    return mean_**(1/2)\n",
    "        \n",
    "## Efficient version:\n",
    "def std_eff(il):\n",
    "    mean = lambda l: sum(l)/len(l)\n",
    "    return mean([(i - mean(il))**2 for i in il])**(1/2)\n",
    "\n",
    "## One-liner:\n",
    "std_ol = lambda l: (sum([(i - (sum(l)/len(l)))**2 for i in l])/len(l))**(1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_ = [1,2,3,4,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4142135623730951"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std_easy(l_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4142135623730951"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std_eff(l_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4142135623730951"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std_ol(l_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4142135623730951"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Or we could import numpy, pandas, stats or any of\n",
    "# the other zillion libraries that do standard deviation!\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "np.std(l_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 6\n",
    "\n",
    "Run multilayer perceptron on MNIST. Compute precision and recall.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import our data\n",
    "\n",
    "We will compare TF's example dataset (MNIST) with the raw image dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import raw image data\n",
    "\n",
    "Importing the dataset this way will make it easy to inspect and visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/train-images-idx3-ubyte.gz\n",
      "Extracting data/train-labels-idx1-ubyte.gz\n",
      "Extracting data/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.contrib.learn.python.learn.datasets.mnist import extract_images, extract_labels\n",
    "\n",
    "with open('data/train-images-idx3-ubyte.gz', 'rb') as f:\n",
    "  train_images = extract_images(f)\n",
    "with open('data/train-labels-idx1-ubyte.gz', 'rb') as f:\n",
    "  train_labels = extract_labels(f)\n",
    "\n",
    "with open('data/t10k-images-idx3-ubyte.gz', 'rb') as f:\n",
    "  test_images = extract_images(f)\n",
    "with open('data/t10k-labels-idx1-ubyte.gz', 'rb') as f:\n",
    "  test_labels = extract_labels(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import TF's example dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-3ff8b16c8389>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /home/torchl/.local/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /home/torchl/.local/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /home/torchl/.local/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/torchl/.local/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting data/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/torchl/.local/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"data/\", one_hot = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualize some samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFsAAABZCAYAAABR/liSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAABPRJREFUeJztnF2IVGUYx3//pl3tY8WVvqSkD7EPN0pxSTG6iOhDL7IIzC3CC2O7UDKoC4kuugwqL4IlMDS9iCIy0EAI26LoQtHEtlxzWjJtzbTQtITWdfbp4pyxSWd2jjOzz5k9vr9lmXPe98x5//zn4T3vO/O8r8yMgA+XpC3gYiKY7Ugw25FgtiPBbEeC2Y4Esx2py2xJj0jaJ2lA0qpGicoqqnVSIykH5IEHgUFgB9BlZv2Nk5ctLq3jvfcAA2b2E4CkD4BFQEWzWzXBJnJFHU02J/9witM2pGrX1WP29cAvJeeDwNxzL5LUDXQDTORy5uqBOppsTrZbb6LrxvwBaWZrzKzTzDpbmDDWzTU19Zh9CJhWcn5DXBaoQD1m7wBmSLpZUiuwBNjcGFnZpOY+28zOSFoBfArkgHVmtqdhyjJIPQ9IzGwLsKVBWjJPmEE6UldkNxv5d+cAsP/htaw+dgsAny3uBKDQn09NV5EQ2Y5kIrJzHbcBsOn+HgCGrYXl7fsA+OiuhwBoa4IvEUJkO5KJyObQbwA8n18CwNaOjWmqqUiIbEcyEdmFP08AcGBwRlTQkaKYUQiR7UgmIjt37TUA3HdH+mPp0QiR7UgmIpu26NefhVN2nFd1dE70A8rkvluBdGeSIbIdyURkFwb2A/DKJ08C8ERXz9m6PU+9BcDsEysBmBYi++IgE5FdZPpL26KDrnR1VCJEtiOZiuwiLcox3IQLKkJkO5LJyB62AiOMpC3jPEJkOxLMdiSY7Ugw25FMPiDLDf0mzT+ajpgSQmQ7ksnILjf0+/Lu9wF4dN6yqGBbn7esENmeZNLs2z9/tmJdvruVfHero5r/qGq2pGmSvpDUL2mPpJVx+RRJWyX9GL+2j73c8U2SyD4DvGhmM4F5wHJJM4FVQK+ZzQB64/OmYEL+srQllKWq2WZ22Mx2xcd/AXuJFi8tAjbEl20AHhsrkVnhgtZBSroJ+Aq4EzhoZpPjcgHHi+eVmKQp5rVarOuHXwF4uu3w/8pblANgwYLoF4aRb/fW3dZ26+WkHau6NC/xA1LSlcBG4AUzO1laZ9EnVvZTk9QtaaekncMMJW0ukyQyW1ILkdHvmdnHcfERSVPj+qlA2SlaWkvz1h+cz/qD8xk552/YCgxbwU1HKUlGIwLWAnvNbHVJ1WZgaXy8FNjUeHnZIskM8l7gGeA7SbvjspeB14APJS0DDgCLx0ZibQytvy46eD1dHaVUNdvMvgYqdf7ZWxs9hmTyuxGA9t3HAOg5Hi0BKS77SJNMTteblZr3G6kFz3G2Jw0fZwfqJ5jtSDDbkWC2I8FsR4LZjgSzHXEdZ0v6HTgF/OHWaOO5ivP132hmV1d7o6vZAJJ2mlmna6MNpB79oRtxJJjtSBpmr0mhzUZSs373PvtiJnQjjriZPR732h4lG+xVSYck7Y7/Fya6n0c3Ml732o6zBqaa2S5JbcA3RMlIi4G/zeyNC7mfV2Sf3WvbzE4Dxb22m5pRssFqwsvscntt1yw6DeJssNnA9rhohaQ+SeuSJpWGB2QCymSDvQ1MB2YBh4E3k9zHy+xxu9d2uWwwMztiZgUzGwHeIeomq+Jl9rjca7tSNlgx7S7mceD7JPdzyRsZx3ttV8oG65I0iyiZ9GfguSQ3CzNIR8ID0pFgtiPBbEeC2Y4Esx0JZjsSzHYkmO3IvyLpl40rTMq3AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFsAAABZCAYAAABR/liSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAABOtJREFUeJztnF9olWUcxz/fze1sNi/cJiI115DtwivLoYFIFxJJFBqI5UVIBHqR/ZEIpKsugyy6iURx5UUQgUFeCBHmRYLJloml0maWqNhWEZa2ue2cXxfvu7nszHM879nzvufx+cDYe95/z/d8+fF7nvc9v+eRmRFwQ13aAu4lgtkOCWY7JJjtkGC2Q4LZDglmOySR2ZLWS/pR0nlJu6olyldU6UONpHpgEHgMuAz0A1vM7Gz15PnFvATXrgLOm9kFAEmfABuAWc1uVM6auC9Bk9lkjBuM202VOi+J2fcDl2Z8vgysvv0kSduAbQBNzGe11iVoMpucsCNlnTfnHaSZ7TWzXjPrbSA3181lmiRmXwE6Znx+IN4XmIUkZvcD3ZK6JDUCzwKHqiPLTyrO2WY2KWkH8AVQD/SZ2ZmqKfOQJB0kZnYYOFwlLd4TniAdEsx2SDDbIV6ZrVwO5XKMblxFd3+O7v5sjeu9MjvrJBqNZI36Re0AHH1/D1+PRV/t7a6nAJj8+WJquqYIke0Qb81e2zTJ2qZJxpe2Mr60NW05gMdmZxGvcvZM6pW9OMqeIo/xNrLzVgBgYn70FbMw4g6R7RDvzR5Z2cDIyoa0ZQD3gNlZwqucbRMTAAxOjNHT0ATAaNd4mpL+Q4hsh3hldn54hPzwCC//9EzaUorildlZJ5jtEK86yGK0tP6TtoRpQmQ7xPvIPvjwPgBeYk3KSkJkO8VLsy8d6yh9Ugp4aXZW8TJnt1y6NZtigaLt+uU9AOTPDqaiCUJkO8XLyK6bvLVdr2j2RaE5/desJSNbUoeko5LOSjoj6ZV4f6ukLyUNxf8Xzr3c2qacNDIJvGZmy4FHgBclLQd2AUfMrBs4En/OBAs/Os6ea53sudZJW10zbXXNDO1sZGhnY6q6SpptZlfN7GS8/Tdwjmjy0gbgQHzaAWDjXIn0hbvK2ZIeBB4CTgCLzexqfOhXYHFVlSVk9zePA7B+3XsA9GyPRiGF1BTdxWhEUgtwEHjVzP6aecyimatFZ69K2iZpQNLABDcTia11yjJbUgOR0R+b2Wfx7mFJS+LjS4CRYtemPTUvj8gjCqNjFEbHnLc/k3JGIwL2A+fM7N0Zhw4BW+PtrcDn1ZfnF+Xk7DXAc8D3kk7F+94A3gI+lfQCcBHYPDcSk7FsXjMAfzy/CoC2/cdT01LSbDM7Bsw2L9u/udFziJdPkAAfPtoHwJ+FUQDaT18HZunFHRHejTjE28h+/dwmADZ1fgdA3Y1o2JlPTVGIbKd4G9mtT0ZPjF9NLyaT3nvsKUJkOySY7ZBgtkOC2Q4JZjuk4nX9KmpM+g24AfzurNHq087/9Xea2aJSFzo1G0DSgJn1Om20iiTRH9KIQ4LZDknD7L0ptFlNKtbvPGffy4Q04hBnZtfiWtt3qAZ7U9IVSafivyfKup+LNFKra23HVQNLzOykpAXAt0TFSJuB62a2+27u5yqyp9faNrNxYGqt7Uxzh2qwinBldrG1tisWnQa3VYMB7JB0WlJfuUWloYMsgyLVYB8Ay4AVwFXgnXLu48rsml1ru1g1mJkNm1nezArAPqI0WRJXZtfkWtuzVYNNld3FPA38UM79nPwGWcNrbc9WDbZF0gqiMpRfgO3l3Cw8QTokdJAOCWY7JJjtkGC2Q4LZDglmOySY7ZBgtkP+BekhdYZlMqmfAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# raw data\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "for i in range(10):\n",
    "    fig, ax = plt.subplots(figsize=(1,1))\n",
    "    image = np.asarray(train_images[i]).squeeze()\n",
    "    im = ax.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFsAAABZCAYAAABR/liSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAABQtJREFUeJztnF2IVGUcxn/Pjvth626lyepu2oaoYBImkoFFgQhhkHljGZQXwRZkFHgjddNlF9VNhLGW4IVkgkEGVoRYIJFoYuVHmuRHa5smQn7Qul//Lubssh8zzjgz+z9nju8PljnnnXPO++zDM+95z8z7vjIzAj7UxC3gdiKY7Ugw25FgtiPBbEeC2Y4Esx0py2xJT0o6IemUpI2VEpVWVOpDjaQMcBJYAXQBB4C1ZnascvLSxaQyzn0YOGVmfwBI2g6sAvKaXad6a6CxjCqTSQ/X6bUbKnRcOWa3AX+O2O8Clo49SFIH0AHQwB0s1fIyqkwm+21PUcdN+A3SzDrNbImZLamlfqKrSzTlmH0emDVi/96oLJCHcsw+AMyVdL+kOuA5YFdlZKWTkttsM+uXtB74BsgAW8zsaMWUpZBybpCY2W5gd4W0pJ7wBOlIWclOMqe3PwjAvmWbAHj+xdcAyOw9FJumkGxHUmu2nWvEzjUyrWYy02omc3l+PZfnx9vPT63ZSSS1bXZj1+ivKmY8exaAgY/iUJMlJNuR1CZ7LP/11wJQF6OGkGxHUpvs5qe6R+3/u7MVgOmcjUMOEJLtSiqTPfDEYr584EMADvdmAGjZdgSAwdhUhWS7ks5k19cwRdmnxb7oB+3Bq1fjlASEZLuSSrPPrE7mv5VMVSkllWY3zYi/fc5FKs1OKsFsR1LV9atpaADg0bbTw2WbLz4ebV2LQdFoQrIdSVey77oTgA9avxou+37fQgDm8GMsmkYSku1IqpLd394yrmz2130xKMlNSLYjqUr2pbd6hrdX/vY0AHXf/QxAEiaNh2Q7kqpkb1q4LdrK8NeVZgBa+7viEzSGgsmWNEvSXknHJB2V9HpUPlXSt5J+j17vnni51U0xzUg/sMHMFgCPAK9KWgBsBPaY2VxgT7QfC5PaZzOpfTZN6qNJfWSUzNaxoCoz6zazQ9H2VeA42clLq4Ct0WFbgWcmSmRauKU2W1I78BCwH2gxs6HxAn8D4zu5TvR8nH2dV5v9bmTABpmyozkuOXkp+vMmaQqwE3jDzK6MfM+yM1dz9q4kdUg6KOlgHzfKElvtFJVsSbVkjd5mZp9HxRckzTSzbkkzgYu5zjWzTqAToFlTK9rdzcybA8CG9tHzptaeXkHz9v2VrKoiFNMbEfAJcNzM3h/x1i5gXbS9Dvii8vLSRTHJXga8APwq6XBU9ibwDrBD0kvAWWDNxEjMT29b9lu+5ZNHN08nP5tPi/3gLacgBc02s31AvnnZ6ZsbPYGk6gnyla7HAGj99AQDMWvJRTJ7/ymlqpM9NM1uZdviqOT6mNdkEZLtSDDbkWC2I8FsR4LZjgSzHQlmO1Lyun4lVSb9Q7YTfMmt0spzD+P132dm0wud6Go2gKSDZrbEtdIKUo7+0Iw4Esx2JA6zO2Oos5KUrN+9zb6dCc2II25mV+Na2zcZDfa2pPOSDkd/K4u6nkczUq1rbUejBmaa2SFJTcBPZAcjrQGumdm7t3I9r2QPr7VtZr3A0FrbieYmo8FKwsvsXGttlyw6DsaMBgNYL+kXSVuKHVQabpBFkGM02CZgDrAI6AbeK+Y6XmZX7VrbuUaDmdkFMxsws0FgM9lmsiBeZlflWtv5RoNFN84hVgNHirmey6/rVbzWdr7RYGslLSI7mPQM8HIxFwtPkI6EG6QjwWxHgtmOBLMdCWY7Esx2JJjtSDDbkf8BN1lyuHQQxsoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TF example data\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "for i in range(10):\n",
    "    fig, ax = plt.subplots(figsize=(1,1))\n",
    "    image = np.asarray(mnist.train.images[i].reshape(28,28)).squeeze()\n",
    "    im = ax.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspect shape of images (array dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# raw data\n",
    "\n",
    "# use the `shape` attribute of the numpy array to see\n",
    "# the dimensions of each images and check how many images\n",
    "# are in the dataset\n",
    "\n",
    "# 60,000 images at (28x28) pixels each with a color depth of 1\n",
    "\n",
    "# conveniently these images already have a 4th dimension which\n",
    "# is necessary for TensorFlow\n",
    "\n",
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.contrib.learn.python.learn.datasets.base.Datasets"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF example data\n",
    "\n",
    "type(mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 784)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's get down to business. Rather than our book we'll be using an ubiquitous learning source out on the web: Towards Data Science, via <a href=\"https://towardsdatascience.com/multi-layer-perceptron-using-tensorflow-9f3e218a4809\"> this article.</a>\n",
    "\n",
    "I've modified some of the steps since I've grabbed the raw data from MNIST. The tutorial above loads the data from another library, which ultimately adds some unecessary steps and leaves out some other more important real-world parts of the data processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be building the following Neural Network model:\n",
    "\n",
    "    784(Input) - 512(Hidden Layer 1) - 256(Hidden Layer 2) - 10 (Output)\n",
    "\n",
    "or as we'd commonly see it:\n",
    "\n",
    "    784-512-256-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our tools\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "\n",
    "# Working in IPython, this saves us from having to initiate any\n",
    "# graphs when we run our models\n",
    "\n",
    "s = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learning parameters\n",
    "\n",
    "Apparently it is difficult to discern good parameters for a dataset you aren't familiar with, but MNIST is a popular dataset and these are considered to be decent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001 # how quickly to adjust the error cost function\n",
    "regularizer_rate = 0.1\n",
    "training_epochs = 15 # number of training cycles\n",
    "batch_size = 100 # size of the batches/chunks of training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Network parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define our initialization variables for 784-512-256-10 MLP model\n",
    "\n",
    "n_classes = len(np.unique(train_labels)) # we know there are 10: (0 - 9 digits)\n",
    "n_output = n_classes # the same in this case\n",
    "n_samples = mnist.train.images.shape[0] # how many images in set... 55000\n",
    "n_features = mnist.train.images.shape[1] # flattened dimension of images: 28x28\n",
    "\n",
    "n_hidden1 = 512 # layer 1 number of features\n",
    "n_hidden2 = 256 # layer 2 number of features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Graph Inputs\n",
    "\n",
    "We define these placeholders for keeping track of variables including input and output variables and any others we are interested in.\n",
    "\n",
    "\n",
    "*Note: `dense layers` and `dropout layers` and beautifully described in <a href=\"https://www.quora.com/In-TensorFlow-what-is-a-dense-and-a-dropout-layer\">this Quora thread</a>.*\n",
    "\n",
    "*In a nutshell, `dropout layers` are a technique used to help prevent overfitting of data. Neurons are randomly selected at each pass to be \"dropped out\", meaning that their weights aren't updated. In turn, this results in the model being less sensitive to their particular weights. This helps the model generalize better.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder('float32', shape= (None, n_features), name = \"featuresx\")\n",
    "Y = tf.placeholder('float32', shape= (None, n_features), name = \"classesy\")\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    \"As dense layers require weights and biases and they need to be initialized with a random normal distribution with zero mean and small variance (1/square root of the number of features).\"\n",
    "                             - Towards Data Science article"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        ## Weights initialized by random normal function with \n",
    "        ##  std_dev = 1/sqrt(number of input features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the weights and biases\n",
    "\n",
    "weights_0 = tf.Variable(tf.random_normal([n_features,n_hidden1], \n",
    "                                    stddev=(1/tf.sqrt(float(n_features))))\n",
    "                                )\n",
    "bias_0 = tf.Variable(tf.random_normal([n_hidden1]))\n",
    "\n",
    "\n",
    "weights_1 = tf.Variable(tf.random_normal([n_hidden1,n_hidden2], \n",
    "                                    stddev=(1/tf.sqrt(float(n_features))))\n",
    "                                )\n",
    "bias_1 = tf.Variable(tf.random_normal([n_hidden2]))\n",
    "\n",
    "\n",
    "weights_2 = tf.Variable(tf.random_normal([n_hidden2,n_output], \n",
    "                                    stddev=(1/tf.sqrt(float(n_hidden2))))\n",
    "                                )\n",
    "bias_2 = tf.Variable(tf.random_normal([n_output]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the MLP model function\n",
    "def multilayer_perceptron(x):\n",
    "    hidden_output_0 = tf.nn.relu(tf.matmul(x, weights_0) + bias_0)\n",
    "    hidden_output_0_0 = tf.nn.dropout(hidden_output_0, keep_prob)\n",
    "        \n",
    "    hidden_output_1 = tf.nn.relu(tf.matmul(hidden_output_0_0, weights_1) + bias_1)\n",
    "    hidden_output_1_1 = tf.nn.dropout(hidden_output_1, keep_prob)\n",
    "    \n",
    "    predicted_y = tf.sigmoid(tf.matmul(hidden_output_1_1, weights_2) + bias_2)\n",
    "    \n",
    "    return predicted_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the model\n",
    "logits = multilayer_perceptron(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function\n",
    "\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(\n",
    "                          logits=logits, labels= Y     )\n",
    "                     )# \\\n",
    "        #+ regularizer_rate*(\n",
    "         #                   tf.reduce_sum(tf.square(bias_0)) + \n",
    "          #                  tf.reduce_sum(tf.square(bias_1))\n",
    "           #                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define optimizer\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate)\n",
    "train_op = optimizer.minimize(loss)\n",
    "\n",
    "# initialize variables\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Test model\n",
    "pred = tf.nn.softmax(logits)  # Apply softmax to logits\n",
    "correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(Y, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Metrics definition\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-83-71c58b5de706>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "## Training parameters\n",
    "batch_size = 128\n",
    "epochs=14\n",
    "dropout_prob = 0.6\n",
    "training_accuracy = []\n",
    "training_loss = []\n",
    "testing_accuracy = []\n",
    "s.run(tf.global_variables_initializer())\n",
    "for epoch in range(epochs):    \n",
    "    arr = np.arange(X_train.shape[0])\n",
    "    np.random.shuffle(arr)\n",
    "    for index in range(0,X_train.shape[0],batch_size):\n",
    "        s.run(optimizer, {input_X: X_train[arr[index:index+batch_size]],\n",
    "                          input_y: y_train[arr[index:index+batch_size]],\n",
    "                        keep_prob:dropout_prob})\n",
    "    training_accuracy.append(s.run(accuracy, feed_dict= {input_X:X_train, \n",
    "                                                         input_y: y_train,keep_prob:1}))\n",
    "    training_loss.append(s.run(loss, {input_X: X_train, \n",
    "                                      input_y: y_train,keep_prob:1}))\n",
    "    \n",
    "    ## Evaluation of model\n",
    "    testing_accuracy.append(accuracy_score(y_test.argmax(1), \n",
    "                            s.run(predicted_y, {input_X: X_test,keep_prob:1}).argmax(1)))\n",
    "    print(\"Epoch:{0}, Train loss: {1:.2f} Train acc: {2:.3f}, Test acc:{3:.3f}\".format(epoch,\n",
    "                                                                    training_loss[epoch],\n",
    "                                                                    training_accuracy[epoch],\n",
    "                                                                   testing_accuracy[epoch]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (128, 10) for Tensor 'classesy_1:0', which has shape '(?, 784)'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-85-e20aa494d327>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0;31m# Run optimizater (back-propagation) and get the loss value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0;31m# Compute average loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1126\u001b[0m                              \u001b[0;34m'which has shape %r'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m                              (np_val.shape, subfeed_t.name,\n\u001b[0;32m-> 1128\u001b[0;31m                               str(subfeed_t.get_shape())))\n\u001b[0m\u001b[1;32m   1129\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Tensor %s may not be fed.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot feed value of shape (128, 10) for Tensor 'classesy_1:0', which has shape '(?, 784)'"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0.\n",
    "        total_batch = int(n_samples/batch_size)\n",
    "        \n",
    "        # Loop through all of the batches\n",
    "        for i in range(total_batch):\n",
    "            batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "            \n",
    "            # Run optimizater (back-propagation) and get the loss value\n",
    "            _, c = sess.run([train_op, loss], feed_dict = {X: batch_x, Y: batch_y})\n",
    "            \n",
    "            # Compute average loss\n",
    "            avg_cost +- c / total_batch\n",
    "            \n",
    "        # Display logs for each epoch step\n",
    "        if epoch % display_step == 0:\n",
    "            print(\"Epoch:\", '%04d' % (epoch+1), \"cost={:.9f}\".format(avg_cost))\n",
    "    print(\"Optimization Finished!\")\n",
    "    \n",
    "     # Test model\n",
    "    pred = tf.nn.softmax(logits)  # Apply softmax to logits\n",
    "    correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(Y, 1))\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "    print(\"Accuracy:\", accuracy.eval({X: mnist.test.images, Y: mnist.test.labels}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/torchl/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py:1702: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 cost188.3108\n",
      "Epoch: 2 cost47.0324\n",
      "Epoch: 3 cost28.3221\n",
      "Epoch: 4 cost18.9097\n",
      "Epoch: 5 cost12.7971\n",
      "Epoch: 6 cost9.1451\n",
      "Epoch: 7 cost6.3738\n",
      "Epoch: 8 cost4.2763\n",
      "Epoch: 9 cost3.1098\n",
      "Epoch: 10 cost2.2220\n",
      "Epoch: 11 cost1.7671\n",
      "Epoch: 12 cost1.3688\n",
      "Epoch: 13 cost1.1266\n",
      "Epoch: 14 cost1.0332\n",
      "Epoch: 15 cost1.0484\n",
      "Model has completed 15 Epochs of training\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9527"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets(\"/tmp/data\", one_hot=True)\n",
    "\n",
    "learning_rate = 0.001 #how quickly to learn\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "\n",
    "n_classes = 10 #MNIST total classes (0 - 9 digits)\n",
    "n_samples = mnist.train.num_examples #(how many images)\n",
    "\n",
    "n_input = 784 #MNIST data input (img shape is 28x28)\n",
    "\n",
    "n_hidden_1 = 512 # 1st layer number of neurons\n",
    "n_hidden_2 = 256 # 2nd layer number of neurons\n",
    "\n",
    "def multilayer_perceptron(x, weights, biases):\n",
    "    '''\n",
    "    x: Placeholder for data input\n",
    "    weights: Dictionary of weights\n",
    "    biases: Dictionary of bias values\n",
    "    '''\n",
    "    # First hidden layer with RELU activation\n",
    "    # X * W + B\n",
    "    layer_1 = tf.add(tf.matmul(x,weights['h1']),biases['b1'])\n",
    "\n",
    "    # RELU(X * W + B) = RELU -> f(x) = max(0,x)\n",
    "    layer_1 = tf.nn.relu(layer_1)\n",
    "\n",
    "    # Second hidden layer\n",
    "    layer_2 = tf.add(tf.matmul(layer_1,weights['h2']),biases['b2'])\n",
    "    layer_2 = tf.nn.relu(layer_2)\n",
    "\n",
    "    # Output layer\n",
    "    out_layer = tf.matmul(layer_2,weights['out']) + biases['out']\n",
    "    return out_layer\n",
    "\n",
    "weights = {\n",
    "'h1':tf.Variable(tf.random_normal([n_input,n_hidden_1])),\n",
    "'h2':tf.Variable(tf.random_normal([n_hidden_1,n_hidden_2])),\n",
    "'out':tf.Variable(tf.random_normal([n_hidden_2,n_classes]))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "'b1':tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "'b2':tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "'out':tf.Variable(tf.random_normal([n_classes]))\n",
    "}\n",
    "\n",
    "x = tf.placeholder('float',[None,n_input])\n",
    "y = tf.placeholder('float',[None,n_classes])\n",
    "\n",
    "pred = multilayer_perceptron(x, weights,biases)\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels= y))\n",
    "optimiser = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "sess.run(init)\n",
    "\n",
    "# 15 loops as we set training_epochs = 15\n",
    "for epoch in range (training_epochs):\n",
    "    # Cost\n",
    "    avg_cost = 0.0\n",
    "    total_batch = int(n_samples/batch_size)\n",
    "    for i in range(total_batch):\n",
    "        # Grab the next batch of training data and labels\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        # Feed dictionary for optimization and loss value\n",
    "        # Returns a tuple, but we only need 'c' the cost\n",
    "        # So we set an underscore as a \"throwaway\"\n",
    "        _,c = sess.run([optimiser,cost],feed_dict={x:batch_x,y:batch_y})\n",
    "        avg_cost += c/total_batch\n",
    "    print(\"Epoch: {} cost{:.4f}\".format(epoch+1,avg_cost))\n",
    "print(\"Model has completed {} Epochs of training\".format(training_epochs))\n",
    "\n",
    "\n",
    "correct_pred = tf.equal(tf.argmax(pred,1),tf.argmax(y,1)) # checks if x==y?\n",
    "correct_pred = tf.cast(correct_pred,'float')\n",
    "accuracy = tf.reduce_mean(correct_pred)\n",
    "accuracy.eval({x:mnist.test.images,y:mnist.test.labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy: 0.9527\n",
      "Precision 0.9527\n",
      "Recall 0.9527\n",
      "f1_score 0.9526999999999999\n",
      "confusion_matrix\n",
      "[[ 963    2    2    0    1    5    3    3    0    1]\n",
      " [   1 1121    4    0    0    2    3    0    3    1]\n",
      " [   9    5  984    6    6    2    1   10    9    0]\n",
      " [   0    4   10  949    1   23    1    9    5    8]\n",
      " [   4    2   10    0  918    4    7    9    7   21]\n",
      " [   1    1    0   14    2  861    4    3    5    1]\n",
      " [   9    4    1    1    7   14  916    3    3    0]\n",
      " [   0    9    6    4    7    1    0  991    3    7]\n",
      " [  13    3    4   20    5   23    2    6  889    9]\n",
      " [   6    6    1   10   10   12    2   25    2  935]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sklearn as sk\n",
    "\n",
    "#metrics\n",
    "y_p = tf.argmax(pred, 1)\n",
    "val_accuracy, y_pred = sess.run([accuracy, y_p], feed_dict={x:mnist.test.images,y:mnist.test.labels})\n",
    "\n",
    "print(\"validation accuracy:\", val_accuracy)\n",
    "y_true = np.argmax(mnist.test.labels,1)\n",
    "print(\"Precision\", sk.metrics.precision_score(y_true, y_pred, average='micro'))\n",
    "print(\"Recall\", sk.metrics.recall_score(y_true, y_pred, average='micro'))\n",
    "print(\"f1_score\", sk.metrics.f1_score(y_true, y_pred, average='micro'))\n",
    "print(\"confusion_matrix\")\n",
    "print(sk.metrics.confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function roc_curve in module sklearn.metrics.ranking:\n",
      "\n",
      "roc_curve(y_true, y_score, pos_label=None, sample_weight=None, drop_intermediate=True)\n",
      "    Compute Receiver operating characteristic (ROC)\n",
      "    \n",
      "    Note: this implementation is restricted to the binary classification task.\n",
      "    \n",
      "    Read more in the :ref:`User Guide <roc_metrics>`.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    \n",
      "    y_true : array, shape = [n_samples]\n",
      "        True binary labels. If labels are not either {-1, 1} or {0, 1}, then\n",
      "        pos_label should be explicitly given.\n",
      "    \n",
      "    y_score : array, shape = [n_samples]\n",
      "        Target scores, can either be probability estimates of the positive\n",
      "        class, confidence values, or non-thresholded measure of decisions\n",
      "        (as returned by \"decision_function\" on some classifiers).\n",
      "    \n",
      "    pos_label : int or str, default=None\n",
      "        Label considered as positive and others are considered negative.\n",
      "    \n",
      "    sample_weight : array-like of shape = [n_samples], optional\n",
      "        Sample weights.\n",
      "    \n",
      "    drop_intermediate : boolean, optional (default=True)\n",
      "        Whether to drop some suboptimal thresholds which would not appear\n",
      "        on a plotted ROC curve. This is useful in order to create lighter\n",
      "        ROC curves.\n",
      "    \n",
      "        .. versionadded:: 0.17\n",
      "           parameter *drop_intermediate*.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    fpr : array, shape = [>2]\n",
      "        Increasing false positive rates such that element i is the false\n",
      "        positive rate of predictions with score >= thresholds[i].\n",
      "    \n",
      "    tpr : array, shape = [>2]\n",
      "        Increasing true positive rates such that element i is the true\n",
      "        positive rate of predictions with score >= thresholds[i].\n",
      "    \n",
      "    thresholds : array, shape = [n_thresholds]\n",
      "        Decreasing thresholds on the decision function used to compute\n",
      "        fpr and tpr. `thresholds[0]` represents no instances being predicted\n",
      "        and is arbitrarily set to `max(y_score) + 1`.\n",
      "    \n",
      "    See also\n",
      "    --------\n",
      "    roc_auc_score : Compute the area under the ROC curve\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    Since the thresholds are sorted from low to high values, they\n",
      "    are reversed upon returning them to ensure they correspond to both ``fpr``\n",
      "    and ``tpr``, which are sorted in reversed order during their calculation.\n",
      "    \n",
      "    References\n",
      "    ----------\n",
      "    .. [1] `Wikipedia entry for the Receiver operating characteristic\n",
      "            <https://en.wikipedia.org/wiki/Receiver_operating_characteristic>`_\n",
      "    \n",
      "    .. [2] Fawcett T. An introduction to ROC analysis[J]. Pattern Recognition\n",
      "           Letters, 2006, 27(8):861-874.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> import numpy as np\n",
      "    >>> from sklearn import metrics\n",
      "    >>> y = np.array([1, 1, 2, 2])\n",
      "    >>> scores = np.array([0.1, 0.4, 0.35, 0.8])\n",
      "    >>> fpr, tpr, thresholds = metrics.roc_curve(y, scores, pos_label=2)\n",
      "    >>> fpr\n",
      "    array([0. , 0. , 0.5, 0.5, 1. ])\n",
      "    >>> tpr\n",
      "    array([0. , 0.5, 0.5, 1. , 1. ])\n",
      "    >>> thresholds\n",
      "    array([1.8 , 0.8 , 0.4 , 0.35, 0.1 ])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(sk.metrics.roc_curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
